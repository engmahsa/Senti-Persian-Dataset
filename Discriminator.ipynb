{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOOcHCEqFB4L",
        "outputId": "58e6da1e-2940-43a4-8756-685dd6a5c3ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "BAqcLx5xFEA_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator:\n",
        "\n",
        "    def __init__(self, tokenizer, model):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = model\n",
        "\n",
        "    def get_cls_embedding(self, text):\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", add_special_tokens=True)\n",
        "        outputs = self.model(**inputs)\n",
        "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "        return cls_embedding\n",
        "\n",
        "    def extract_features(self, texts):\n",
        "        features = []\n",
        "        for text in texts:\n",
        "            cls_embedding = self.get_cls_embedding(text)\n",
        "            features.append(cls_embedding.detach().numpy().squeeze())\n",
        "        features = np.vstack(features)\n",
        "        return features\n",
        "\n",
        "    def discriminator_loss(self, real_features, generated_features):\n",
        "        real_features = torch.tensor(real_features)\n",
        "        generated_features = torch.tensor(generated_features)\n",
        "        tmp2 = torch.mean(torch.multiply(real_features.float(), generated_features.float()))\n",
        "        loss = torch.tensor(-tmp2, requires_grad=True)\n",
        "        return loss\n",
        "\n",
        "    def similarity(self, input_text, generated_texts):\n",
        "        orig_text_list = input_text.split()\n",
        "        text1 = \" \".join(orig_text_list)\n",
        "        cls_embedding1 = self.get_cls_embedding(text1)\n",
        "\n",
        "        best_suggestions = {}\n",
        "        real_features = self.extract_features([text1])\n",
        "\n",
        "        for generated_text in generated_texts:\n",
        "            cls_embedding2 = self.get_cls_embedding(generated_text)\n",
        "            similarity = cosine_similarity(cls_embedding1.detach().numpy().squeeze().reshape(1, -1), cls_embedding2.detach().numpy().squeeze().reshape(1, -1))\n",
        "            similarity_score = similarity.item()\n",
        "\n",
        "            generated_features = self.extract_features([generated_text])\n",
        "            loss = self.discriminator_loss(real_features, generated_features)\n",
        "\n",
        "            word = generated_text  # Assuming the whole generated text is considered as a suggestion\n",
        "            if word not in best_suggestions or loss.item() < best_suggestions[word]['loss']:\n",
        "                best_suggestions[word] = {'suggestion': generated_text, 'loss': loss.item(), 'similarity': similarity_score}\n",
        "                print(f\"Word: {generated_text}, Loss: {loss.item()}, Cosine Similarity: {similarity_score}\")\n",
        "\n",
        "        # Output the best suggestions for each word\n",
        "        for word, suggestion_info in best_suggestions.items():\n",
        "            print(f\"suggestion for '{word}': {suggestion_info['suggestion']}, Loss: {suggestion_info['loss']}, Cosine Similarity: {suggestion_info['similarity']}\")\n",
        "\n",
        "def main():\n",
        "    # Define the input text and generated texts\n",
        "    generated_texts = [\"من درباره این سریال حرفی ندارم\", \"من درباره این فیلم نظری ندارم\", \"من به این داستان نظری ندارم\", \"من درباره این سریال اظهارنظری ندارم\"]\n",
        "    input_text = \"من درباره این سریال نظری ندارم\"\n",
        "\n",
        "    # Initialize the tokenizer and model\n",
        "    model_name = \"HooshvareLab/bert-fa-base-uncased\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    # Initialize the discriminator\n",
        "    discriminator = Discriminator(tokenizer, model)\n",
        "\n",
        "    # Calculate similarity and loss\n",
        "    discriminator.similarity(input_text, generated_texts)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFgjt-gpqP5k",
        "outputId": "14bc9739-4b10-40d1-cce7-a52c916bcbea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "<ipython-input-9-731336d4a662>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss = torch.tensor(-tmp2, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: من درباره این سریال حرفی ندارم, Loss: -0.7757735252380371, Cosine Similarity: 0.9617154598236084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-731336d4a662>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss = torch.tensor(-tmp2, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: من درباره این فیلم نظری ندارم, Loss: -0.7806766629219055, Cosine Similarity: 0.9703912734985352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-731336d4a662>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss = torch.tensor(-tmp2, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: من به این داستان نظری ندارم, Loss: -0.6737119555473328, Cosine Similarity: 0.8468949794769287\n",
            "Word: من درباره این سریال اظهارنظری ندارم, Loss: -0.7619295120239258, Cosine Similarity: 0.9509677290916443\n",
            "suggestion for 'من درباره این سریال حرفی ندارم': من درباره این سریال حرفی ندارم, Loss: -0.7757735252380371, Cosine Similarity: 0.9617154598236084\n",
            "suggestion for 'من درباره این فیلم نظری ندارم': من درباره این فیلم نظری ندارم, Loss: -0.7806766629219055, Cosine Similarity: 0.9703912734985352\n",
            "suggestion for 'من به این داستان نظری ندارم': من به این داستان نظری ندارم, Loss: -0.6737119555473328, Cosine Similarity: 0.8468949794769287\n",
            "suggestion for 'من درباره این سریال اظهارنظری ندارم': من درباره این سریال اظهارنظری ندارم, Loss: -0.7619295120239258, Cosine Similarity: 0.9509677290916443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-731336d4a662>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss = torch.tensor(-tmp2, requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}